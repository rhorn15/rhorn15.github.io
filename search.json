[
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Ryan Horn’s Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nHoliday Movies\n\n\n\n\n\n\n\n\nApr 9, 2025\n\n\nRyan Horn\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nSpotify Analytics\n\n\n\n\n\n\n\n\nMar 31, 2025\n\n\nRyan Horn\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nPython Basics\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\nRyan Horn\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nRyan Horn\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nRestaurant Inspections\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nRyan Horn\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nNFL 2022 Data\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nRyan Horn\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nRyan Horn\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pandas_basics.html#creating-a-series",
    "href": "pandas_basics.html#creating-a-series",
    "title": "Pandas Basics",
    "section": "Creating a Series",
    "text": "Creating a Series\n\n\n# Creating a Series from a list\ndata = [10, 20, 30, 40, 50]\nseries = pd.Series(data)\nseries\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\n10\n\n\n1\n20\n\n\n2\n30\n\n\n3\n40\n\n\n4\n50\n\n\n\n\ndtype: int64"
  },
  {
    "objectID": "pandas_basics.html#creating-a-dataframe",
    "href": "pandas_basics.html#creating-a-dataframe",
    "title": "Pandas Basics",
    "section": "Creating a DataFrame",
    "text": "Creating a DataFrame\n\n\n# Creating a DataFrame from a dictionary\ndata = {\n    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"Age\": [25, 30, 35],\n    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n}\ndf = pd.DataFrame(data)\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n0\nAlice\n25\nNew York\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#exploring-data",
    "href": "pandas_basics.html#exploring-data",
    "title": "Pandas Basics",
    "section": "Exploring Data",
    "text": "Exploring Data\n\n\n# Display the first few rows\ndf.head()\n\n# Display the shape of the DataFrame\nprint(\"Shape:\", df.shape)\n\n# Display summary statistics\ndf.describe()\n\nShape: (3, 3)\n\n\n\n  \n    \n\n\n\n\n\n\nAge\n\n\n\n\ncount\n3.0\n\n\nmean\n30.0\n\n\nstd\n5.0\n\n\nmin\n25.0\n\n\n25%\n27.5\n\n\n50%\n30.0\n\n\n75%\n32.5\n\n\nmax\n35.0"
  },
  {
    "objectID": "pandas_basics.html#selecting-data",
    "href": "pandas_basics.html#selecting-data",
    "title": "Pandas Basics",
    "section": "Selecting Data",
    "text": "Selecting Data\n\n# Selecting a single column\ndf[\"Name\"]\n\n\n\n\n\n\n\n\nName\n\n\n\n\n0\nAlice\n\n\n1\nBob\n\n\n2\nCharlie\n\n\n\n\ndtype: object\n\n\n\n# Selecting multiple columns\ndf[[\"Name\", \"City\"]]\n\n\n  \n    \n\n\n\n\n\n\nName\nCity\n\n\n\n\n0\nAlice\nNew York\n\n\n1\nBob\nLos Angeles\n\n\n2\nCharlie\nChicago\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Selecting rows by index\ndf.iloc[0]\n\n\n\n\n\n\n\n\n0\n\n\n\n\nName\nAlice\n\n\nAge\n25\n\n\nCity\nNew York\n\n\n\n\ndtype: object"
  },
  {
    "objectID": "pandas_basics.html#filtering-data",
    "href": "pandas_basics.html#filtering-data",
    "title": "Pandas Basics",
    "section": "Filtering Data",
    "text": "Filtering Data\n\n# Filtering rows where Age is greater than 25\nfiltered_df = df[df[\"Age\"] &gt; 25]\nfiltered_df\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#adding-a-new-column",
    "href": "pandas_basics.html#adding-a-new-column",
    "title": "Pandas Basics",
    "section": "Adding a New Column",
    "text": "Adding a New Column\n\n\n# Adding a new column\ndf[\"Salary\"] = [50000, 60000, 70000]\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\nSalary\n\n\n\n\n0\nAlice\n25\nNew York\n50000\n\n\n1\nBob\n30\nLos Angeles\n60000\n\n\n2\nCharlie\n35\nChicago\n70000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n    ## Conclusion\n\n    This notebook covers the basic operations of pandas. You can explore more advanced features like merging,\n    joining, and working with time series data in pandas documentation: https://pandas.pydata.org/docs/"
  },
  {
    "objectID": "DANL210_proj.html#salary-distribution-among-teams",
    "href": "DANL210_proj.html#salary-distribution-among-teams",
    "title": "Data Analysis Project",
    "section": "Salary Distribution Among Teams",
    "text": "Salary Distribution Among Teams\nLet’s start with the salary distribution among teams using seaborn for visualization. ​​\n\n\n# Handle missing values in 'Salary' by replacing them with the median salary\nmedian_salary = nba['Salary'].median()\nnba['Salary'].fillna(median_salary, inplace=True)\n\n/var/folders/_m/d6jf0jhd2zzdfd5kzdhl_24w0000gn/T/ipykernel_79892/1671011424.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  nba['Salary'].fillna(median_salary, inplace=True)\n\n\n\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Calculate total salary by team\nteam_salary = (\n    nba\n    .groupby('Team')['Salary']\n    .sum()\n    .reset_index()\n    .sort_values(by='Salary', ascending=False)\n)\n\n# Plot total salary by team\nplt.figure(figsize=(10, 16))\nsns.barplot(data = team_salary,\n            x = 'Salary', y = 'Team',\n            palette = 'coolwarm')\nplt.title('Total Salary Distribution Among NBA Teams')\nplt.xlabel('Total Salary')\nplt.ylabel('Team')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nThe visualization above displays the total salary distribution among NBA teams, with teams sorted by their total salary expenditure. This bar plot reveals which teams are the biggest spenders on player salaries and which are more conservative. The color gradient provides a visual cue to easily distinguish between the higher and lower spending teams.\nNotice that Portland Trail Blazers has the highest total salary followed by Golden State Warriors and Philadelphia 76ers, and Memphis Grizzlies has the lowest total salary."
  },
  {
    "objectID": "DANL210_proj.html#player-age-distribution",
    "href": "DANL210_proj.html#player-age-distribution",
    "title": "Data Analysis Project",
    "section": "Player Age Distribution",
    "text": "Player Age Distribution\nNext, let’s explore the Player Age Distribution across the NBA. We’ll create a histogram to visualize how player ages are distributed, which will help us understand if the league trends younger, older, or has a balanced age mix. ​​\n\n# Convert 'Birthday' column to datetime format\nfrom dateutil import parser\n# nba['Birthday'] = nba['Birthday'].apply(lambda x: parser.parse(x))\n\n# Now, let's calculate the age of each player\n# nba['Age'] = (datetime.now() - nba['Birthday']).dt.days // 365\n\n# Plot the age distribution of NBA players\nplt.figure(figsize=(10, 6))\nsns.histplot(nba['Age'],\n             bins = 15,\n             kde = True,\n             color = 'skyblue')\nplt.title('Age Distribution of NBA Players')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()\n\n\n/Users/bchoe/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nThe histogram above shows the age distribution of NBA players, with a kernel density estimate (KDE) overlay to indicate the distribution shape. The plot helps identify the common ages for NBA players and whether there are significant numbers of very young or older players.\nNotice that the majority of players fall within an age range from 24 to 34. There are few players whose age is above 40."
  },
  {
    "objectID": "DANL210_proj.html#position-wise-salary-insights",
    "href": "DANL210_proj.html#position-wise-salary-insights",
    "title": "Data Analysis Project",
    "section": "Position-wise Salary Insights",
    "text": "Position-wise Salary Insights\nMoving on to Position-wise Salary Insights, we’ll examine how average salaries differ across player positions. This analysis could reveal which positions are typically higher-paid, potentially reflecting their value on the basketball court. Let’s create a box plot to visualize the salary distribution for each position. ​​\n\n# Plot salary distribution by player position\nplt.figure(figsize=(10, 6))\nsns.boxplot(data = nba,\n            x = 'Position', y = 'Salary',\n            palette = 'Set2')\nplt.title('Salary Distribution by Position')\nplt.xlabel('Position')\nplt.ylabel('Salary')\nplt.show()\n\n\n\n\n\n\n\n\nThe box plot above illustrates the salary distribution by player position, showcasing the variation in salaries among different positions within the NBA. PG-SG has the highest median salary."
  },
  {
    "objectID": "DANL210_proj.html#top-10-highest-paid-players",
    "href": "DANL210_proj.html#top-10-highest-paid-players",
    "title": "Data Analysis Project",
    "section": "Top 10 Highest Paid Players",
    "text": "Top 10 Highest Paid Players\nLastly, we’ll identify the Top 10 Highest Paid Players in the NBA. Let’s visualize this information.\n\n# Identify the top 10 highest paid players\ntop_10_salaries = nba.sort_values(by='Salary', ascending=False).head(10)\n\n# Plot the top 10 highest paid players\nplt.figure(figsize=(12, 8))\nsns.barplot(data = top_10_salaries,\n            x = 'Salary', y = 'PlayerName',\n            palette = 'viridis')\nplt.title('Top 10 Highest Paid NBA Players')\nplt.xlabel('Salary')\nplt.ylabel('Player')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar plot above reveals the top 10 highest-paid NBA players, showcasing those who stand at the pinnacle of the league in terms of salary. This visualization not only highlights the star players who command the highest salaries but also may reflect their marketability, performance, and contribution to their respective teams."
  },
  {
    "objectID": "DANL200_proj.html",
    "href": "DANL200_proj.html",
    "title": "DANL Project",
    "section": "",
    "text": "About this project 👏\nIn this project my group and I are using a data set of motor cars to determine the fastest cars, then we will decipher some parameters by what makes them the best."
  },
  {
    "objectID": "DANL200_proj.html#introduction",
    "href": "DANL200_proj.html#introduction",
    "title": "DANL Project",
    "section": "",
    "text": "About this project 👏\nIn this project my group and I are using a data set of motor cars to determine the fastest cars, then we will decipher some parameters by what makes them the best."
  },
  {
    "objectID": "DANL200_proj.html#summary-statistics",
    "href": "DANL200_proj.html#summary-statistics",
    "title": "DANL Project",
    "section": "1.1 Summary Statistics",
    "text": "1.1 Summary Statistics\n\nrmarkdown::paged_table(mtcars)\n\n\n  \n\n\n\n\n1.1.1 Summary Statistics\n\nskim(mtcars) %&gt;% \n  select(-n_missing)\n\n\nData summary\n\n\nName\nmtcars\n\n\nNumber of rows\n32\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nmpg\n1\n20.09\n6.03\n10.40\n15.43\n19.20\n22.80\n33.90\n▃▇▅▁▂\n\n\ncyl\n1\n6.19\n1.79\n4.00\n4.00\n6.00\n8.00\n8.00\n▆▁▃▁▇\n\n\ndisp\n1\n230.72\n123.94\n71.10\n120.83\n196.30\n326.00\n472.00\n▇▃▃▃▂\n\n\nhp\n1\n146.69\n68.56\n52.00\n96.50\n123.00\n180.00\n335.00\n▇▇▆▃▁\n\n\ndrat\n1\n3.60\n0.53\n2.76\n3.08\n3.70\n3.92\n4.93\n▇▃▇▅▁\n\n\nwt\n1\n3.22\n0.98\n1.51\n2.58\n3.33\n3.61\n5.42\n▃▃▇▁▂\n\n\nqsec\n1\n17.85\n1.79\n14.50\n16.89\n17.71\n18.90\n22.90\n▃▇▇▂▁\n\n\nvs\n1\n0.44\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▆\n\n\nam\n1\n0.41\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▆\n\n\ngear\n1\n3.69\n0.74\n3.00\n3.00\n4.00\n4.00\n5.00\n▇▁▆▁▂\n\n\ncarb\n1\n2.81\n1.62\n1.00\n2.00\n2.00\n4.00\n8.00\n▇▂▅▁▁"
  },
  {
    "objectID": "DANL200_proj.html#explanation",
    "href": "DANL200_proj.html#explanation",
    "title": "DANL Project",
    "section": "2.1 Explanation",
    "text": "2.1 Explanation\nThis graph gives a visual representation of the quarter mile times of various motor cars in descending order."
  },
  {
    "objectID": "DANL200_proj.html#explanation-1",
    "href": "DANL200_proj.html#explanation-1",
    "title": "DANL Project",
    "section": "3.1 Explanation",
    "text": "3.1 Explanation\nThis graph allows you to visually see the difference in quarter mile time and how it varies by the number of cylinders in the vehicle. As you can see the vehicles with fewer cylinders can generally be seen with a slower quarter mile time."
  },
  {
    "objectID": "DANL200_proj.html#explanation-2",
    "href": "DANL200_proj.html#explanation-2",
    "title": "DANL Project",
    "section": "4.1 Explanation",
    "text": "4.1 Explanation\nThis visualization is similar to the last one except that this graph also shows the weight distribution among the vehicles, generally we can see that cars with more cylinders will be heavier than their counterparts."
  },
  {
    "objectID": "DANL200_proj.html#explanation-3",
    "href": "DANL200_proj.html#explanation-3",
    "title": "DANL Project",
    "section": "5.1 Explanation",
    "text": "5.1 Explanation\nHere we can decipher the quarter mile time in terms of the vehicles horse power and engine type, as we can see, as horse power grows, the quarter mile time goes down. At the same time most vehicles contain a V-Shaped engine that how the faster quarter mile times."
  },
  {
    "objectID": "DANL200_proj.html#explanation-4",
    "href": "DANL200_proj.html#explanation-4",
    "title": "DANL Project",
    "section": "6.1 Explanation",
    "text": "6.1 Explanation\nFinally, this visualization shows how 3 variables (weight, cylinders, and horsepower) differ in each fastest car (from left to right)."
  },
  {
    "objectID": "seaborn_basics.html",
    "href": "seaborn_basics.html",
    "title": "Seaborn Example",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Sample data\ndata = {\n    'Category': ['A', 'B', 'C', 'D'],\n    'Values': [23, 45, 56, 78]\n}\ndf = pd.DataFrame(data)\n\n# Create a barplot\nsns.set(style=\"whitegrid\")  # Optional: Set a clean grid style\nplt.figure(figsize=(8, 6))  # Set the figure size\nsns.barplot(data=df, x='Category', y='Values', palette='viridis')\n\n# Customize the plot\nplt.title(\"Bar Plot Example\", fontsize=16)\nplt.xlabel(\"Category\", fontsize=12)\nplt.ylabel(\"Values\", fontsize=12)\n\n# Show the plot\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=df, x='Category', y='Values', palette='viridis')"
  },
  {
    "objectID": "posts/Holiday Movies/index.html",
    "href": "posts/Holiday Movies/index.html",
    "title": "Holiday Movies",
    "section": "",
    "text": "load the data\n\nimport pandas as pd\nfrom itables import init_notebook_mode, show\ninit_notebook_mode(all_interactive=False)\n\n# Load the holiday movies dataset\nholiday_movies = pd.read_csv(\"https://bcdanl.github.io/data/holiday_movies.csv\")\n\n# Load the holiday movie genres dataset\nholiday_movie_genres = pd.read_csv(\"https://bcdanl.github.io/data/holiday_movie_genres.csv\")\n\n\n\n\n\n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nThis is the init_notebook_mode cell from ITables v2.2.4\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\n\nExplore data through various pandas operations\n\ntotal_movies = holiday_movies.shape[0]\nprint('Total number of movies:', total_movies)\n\ntotal_genres = holiday_movie_genres['genres'].value_counts()\nprint('Number of movies per genre:')\nprint(total_genres)\n\nTotal number of movies: 2265\nNumber of movies per genre:\ngenres\nComedy         1025\nDrama           828\nRomance         737\nFamily          707\nAnimation       268\nFantasy         185\nAdventure       117\nDocumentary     101\nShort            96\nMusic            91\nMusical          78\nHorror           63\nCrime            44\nMystery          37\nThriller         32\nAction           31\nSci-Fi           14\nHistory          13\nWar               9\nWestern           6\nBiography         6\nSport             5\nFilm-Noir         2\nTalk-Show         2\nNews              1\nReality-TV        1\nName: count, dtype: int64\n\n\n\nsorted_movies = holiday_movies.sort_values(by='average_rating', ascending=False)\nprint('Top 5 movies by average rating')\nprint(sorted_movies[['primary_title','average_rating']].head())\n\nTop 5 movies by average rating\n                       primary_title  average_rating\n1204         NLO Spirit of Christmas            10.0\n1433         Bringing Back Christmas             9.9\n1522               Christmas Bone Us             9.8\n1601    Cheap vs. Expensive Xmas Day             9.5\n519   Marie Osmond's Merry Christmas             9.4\n\n\n\nhighly_rated_movies = holiday_movies[holiday_movies['average_rating'] &gt;= 8]\nprint(\"Movies with average rating &gt;= 8:\")\nprint(highly_rated_movies[['primary_title', 'average_rating']].head())\n\nMovies with average rating &gt;= 8:\n                        primary_title  average_rating\n45                  A Christmas Carol             8.1\n48                      Roman Holiday             8.0\n65          A Charlie Brown Christmas             8.3\n68    How the Grinch Stole Christmas!             8.3\n73  The Homecoming: A Christmas Story             8.3\n\n\n\nmovies_2000_onwards = holiday_movies[holiday_movies['year'] &gt;= 2000]\nprint(\"Movies released in or after 2000:\")\nshow(movies_2000_onwards[['primary_title', 'year']])\n\nMovies released in or after 2000:\n\n\n\n\n    \n      \n      primary_title\n      year\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nmovies_with_genres = pd.merge(holiday_movies, holiday_movie_genres, on='tconst', how='left')\nprint('Movies with their genres:')\nshow(movies_with_genres[['primary_title', 'genres']])\n\nMovies with their genres:\n\n\n\n\n    \n      \n      primary_title\n      genres\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)"
  },
  {
    "objectID": "posts/Beer Markets/index.html",
    "href": "posts/Beer Markets/index.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Here is some analytics in relation to Beer Markets!\n\n\n\n\n\n\n\n\n\n\nThis scatter plot visualizes the relationship between the quantity of items purchased and the corresponding dollar spent.\n\n\n\n\n\n\n\n\n\nThis bar plot shows the total dollar spent on each beer brand.\n\n\n\n\n\n\n\n\n\nThis box plot visualizes the distribution of the price per fl.oz. based on whether the item was promoted."
  },
  {
    "objectID": "posts/Spotify 2025/index.html",
    "href": "posts/Spotify 2025/index.html",
    "title": "Spotify Analytics",
    "section": "",
    "text": "import pandas as pd\nfrom itables import init_notebook_mode,show\ninit_notebook_mode(all_interactive=False)\n\nspotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')\n\nshow(spotify)\n\n\n\n\n\n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nThis is the init_notebook_mode cell from ITables v2.2.4\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\n\n    \n      \n      pid\n      playlist_name\n      pos\n      artist_name\n      track_name\n      duration_ms\n      album_name\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)"
  },
  {
    "objectID": "posts/Spotify 2025/index.html#below-is-analytics-of-multiple-different-parameters-related-to-the-following-spotify-dataframe.",
    "href": "posts/Spotify 2025/index.html#below-is-analytics-of-multiple-different-parameters-related-to-the-following-spotify-dataframe.",
    "title": "Spotify Analytics",
    "section": "",
    "text": "import pandas as pd\nfrom itables import init_notebook_mode,show\ninit_notebook_mode(all_interactive=False)\n\nspotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')\n\nshow(spotify)\n\n\n\n\n\n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nThis is the init_notebook_mode cell from ITables v2.2.4\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\n\n    \n      \n      pid\n      playlist_name\n      pos\n      artist_name\n      track_name\n      duration_ms\n      album_name\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)"
  },
  {
    "objectID": "posts/Spotify 2025/index.html#this-code-displays-all-the-tracks-of-one-of-my-favorite-artists-oasis-in-this-data-frame.",
    "href": "posts/Spotify 2025/index.html#this-code-displays-all-the-tracks-of-one-of-my-favorite-artists-oasis-in-this-data-frame.",
    "title": "Spotify Analytics",
    "section": "This code displays all the tracks of one of my favorite artists (Oasis) in this data frame.",
    "text": "This code displays all the tracks of one of my favorite artists (Oasis) in this data frame.\n\noasis_df = (\n    spotify\n    [spotify['artist_name'] == 'Oasis']\n    .drop_duplicates(subset='track_name')\n)\nshow(oasis_df)\n\n\n\n    \n      \n      pid\n      playlist_name\n      pos\n      artist_name\n      track_name\n      duration_ms\n      album_name\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)"
  },
  {
    "objectID": "posts/Spotify 2025/index.html#this-code-displays-the-total-number-of-tracks-by-oasis",
    "href": "posts/Spotify 2025/index.html#this-code-displays-the-total-number-of-tracks-by-oasis",
    "title": "Spotify Analytics",
    "section": "This code displays the total number of tracks by Oasis",
    "text": "This code displays the total number of tracks by Oasis\n\n(\n    oasis_df\n    .value_counts(['track_name']).shape[0]\n)\n\n12"
  },
  {
    "objectID": "posts/Spotify 2025/index.html#this-code-changes-the-duration-from-ms-to-minutes-to-make-it-more-understandable-then-prints-the-top-5-longest-songs-by-oasis",
    "href": "posts/Spotify 2025/index.html#this-code-changes-the-duration-from-ms-to-minutes-to-make-it-more-understandable-then-prints-the-top-5-longest-songs-by-oasis",
    "title": "Spotify Analytics",
    "section": "This code changes the duration from ms to minutes to make it more understandable then prints the top 5 longest songs by Oasis",
    "text": "This code changes the duration from ms to minutes to make it more understandable then prints the top 5 longest songs by Oasis\n\noasis_df['duration_sec'] = oasis_df['duration_ms'] / 1000\noasis_df['duration_min'] = oasis_df['duration_sec'] / 60\n\nsorted_oasis = (\n    oasis_df\n    .sort_values(by='duration_min', ascending=False)\n    [['track_name', 'duration_min']]\n    .head(5)\n)\n\nshow(sorted_oasis)\n\n\n\n    \n      \n      track_name\n      duration_min\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)"
  },
  {
    "objectID": "posts/Python Basics/index.html",
    "href": "posts/Python Basics/index.html",
    "title": "Python Basics",
    "section": "",
    "text": "Lecture 4\nIn lecture 4 we worked with various aspects of python including, values, variables, types, assignments, basic code, and comment styles.\n\n\nLecture 5\nIn lecture 5 we expanded on what we learned in lecture 4 and introduced many more aspects of python. Some of these included Booleans, conditions, and if statements. On top of that we started using slicing methods for strings and lists and many more.\n\n\nClasswork 4\nIn classwork 4 we started with using pythons syntax to solve an algabreaic equation. We then practiced with lists, slicing, while and for loops, and importing libraries."
  },
  {
    "objectID": "posts/Restaurant Inspection/index.html",
    "href": "posts/Restaurant Inspection/index.html",
    "title": "Restaurant Inspections",
    "section": "",
    "text": "Listed here are some analytics related to restaurants in NYC.\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\n\nAs we can see from the graph above, data from NYC restaurants, critical score varies more as the you move from category A, B, and C.\n\n\n\n\n\n\n\n\n\nThis bar plot shows the top 10 cuisine types based on the number of restaurants.\n\n\n\n\n\n\n\n\n\nThis histogram visualizes the distribution of inspection scores for restaurants."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Thank you for checking this out! This blog is to display some analytics of various data sets, hope you enjoy!"
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html",
    "href": "posts/NFL 2022 Data/index.html",
    "title": "NFL 2022 Data",
    "section": "",
    "text": "Here is some analytics in relation to Data from the 2022 NFL season!"
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html#q2a",
    "href": "posts/NFL 2022 Data/index.html#q2a",
    "title": "NFL 2022 Data",
    "section": "Q2a",
    "text": "Q2a\nIn data.frame, NFL2022_stuffs, remove observations for which values of posteam is missing.\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nAnswer:\n\nNFL2022_stuffs_cleaned &lt;- NFL2022_stuffs %&gt;% \n  filter(!is.na(posteam))\n\nhead(NFL2022_stuffs_cleaned)\n\n  play_id         game_id drive week posteam qtr down half_seconds_remaining\n1      43 2022_01_BAL_NYJ     1    1     NYJ   1   NA                   1800\n2      68 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1796\n3      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n4     115 2022_01_BAL_NYJ     1    1     NYJ   1    2                   1765\n5     136 2022_01_BAL_NYJ     1    1     NYJ   1    3                   1741\n6     172 2022_01_BAL_NYJ     1    1     NYJ   1    4                   1733\n  pass        wp\n1    0 0.5462618\n2    0 0.5469690\n3    1 0.5725734\n4    0 0.5545366\n5    1 0.5401673\n6    0 0.4880532"
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html#q2b",
    "href": "posts/NFL 2022 Data/index.html#q2b",
    "title": "NFL 2022 Data",
    "section": "Q2b",
    "text": "Q2b\n-Summarize the mean value of pass for each posteam when all the following conditions hold:\n\nwp is greater than 20% and less than 75%;\ndown is less than or equal to 2; and\nhalf_seconds_remaining is greater than 120\n\nAnswer:\n\nfiltered_data &lt;- NFL2022_stuffs %&gt;%\n  filter(\n    !is.na(posteam),       \n    wp &gt; 0.2 & wp &lt; 0.75,   \n    down &lt;= 2,              \n    half_seconds_remaining &gt; 120  \n  )\n\nsummary_data &lt;- filtered_data %&gt;%\n  group_by(posteam) %&gt;%\n  summarize(mean_pass = mean(pass, na.rm = TRUE))\n\nprint(summary_data)\n\n# A tibble: 32 × 2\n   posteam mean_pass\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 ARI         0.553\n 2 ATL         0.4  \n 3 BAL         0.520\n 4 BUF         0.604\n 5 CAR         0.458\n 6 CHI         0.420\n 7 CIN         0.657\n 8 CLE         0.491\n 9 DAL         0.474\n10 DEN         0.493\n# ℹ 22 more rows"
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html#q2c",
    "href": "posts/NFL 2022 Data/index.html#q2c",
    "title": "NFL 2022 Data",
    "section": "Q2c",
    "text": "Q2c\n-Provide both (1) a ggplot code with geom_point() using the resulting data.frame in Q2b and (2) a simple comments to describe the mean value of pass for each posteam. In the ggplot, reorder the posteam categories based on the mean value of pass in ascending or in descending order.\nAnswer:\n\nlibrary(ggplot2)\nresult &lt;- NFL2022_stuffs %&gt;%\n  filter(\n    wp &gt; 0.2 & wp &lt; 0.75,\n    down &lt;= 2,\n    half_seconds_remaining &gt; 120\n  ) %&gt;%\n  group_by(posteam) %&gt;%\n  summarise(mean_pass = mean(pass, na.rm = TRUE))\n\nresult$posteam &lt;- factor(result$posteam, levels = result$posteam[order(result$mean_pass)])\n\nggplot(result, aes(x = posteam, y = mean_pass)) +\n  geom_point() +\n  labs(title = \"Mean Value of Pass for Each posteam\",\n       x = \"posteam\",\n       y = \"Mean Pass Value\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html#q2d",
    "href": "posts/NFL 2022 Data/index.html#q2d",
    "title": "NFL 2022 Data",
    "section": "Q2d",
    "text": "Q2d\n\nCreate the data.frame, NFL2022_stuffs_EPA, that includes\n\n\nAll the variables in the data.frame, NFL2022_stuffs;\nThe variables, passer, receiver, and epa, from the data.frame, NFL2022_epa. by joining the two data.frames.\n\n\nIn the resulting data.frame, NFL2022_stuffs_EPA, remove observations with NA in passer.\n\nAnswer:\n\nNFL2022_epa &lt;- read.csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\nNFL2022_stuffs_EPA &lt;- left_join(NFL2022_stuffs, NFL2022_epa, by = c(\"play_id\", \"game_id\", \"drive\", \"posteam\"))\n\nNFL2022_stuffs_EPA &lt;- NFL2022_stuffs_EPA %&gt;%\n  filter(!is.na(passer))\n\nhead(NFL2022_stuffs_EPA)\n\n  play_id         game_id drive week posteam qtr down half_seconds_remaining\n1      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n2     136 2022_01_BAL_NYJ     1    1     NYJ   1    3                   1741\n3     202 2022_01_BAL_NYJ     2    1     BAL   1    1                   1722\n4     230 2022_01_BAL_NYJ     2    1     BAL   1    2                   1701\n5     301 2022_01_BAL_NYJ     2    1     BAL   1    2                   1579\n6     412 2022_01_BAL_NYJ     3    1     NYJ   1    2                   1451\n  pass        wp   receiver    passer         epa\n1    1 0.5725734  Mi.Carter  J.Flacco -0.49219242\n2    1 0.5401673       &lt;NA&gt;  J.Flacco -2.40220026\n3    1 0.4958201  R.Bateman L.Jackson  0.07512748\n4    1 0.4965942 D.Duvernay L.Jackson -0.10512029\n5    1 0.5067707 D.Duvernay L.Jackson  0.41113183\n6    1 0.5001284    Br.Hall  J.Flacco -0.17972556"
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html#q2e",
    "href": "posts/NFL 2022 Data/index.html#q2e",
    "title": "NFL 2022 Data",
    "section": "Q2e",
    "text": "Q2e\n\nProvide both (1) a single ggplot and (2) a simple comment to describe the NFL weekly trend of weekly mean value of epa for each of the following two passers,\n\n\n“J.Allen”\n“P.Mahomes”\n\nAnswer:\n\nggplot(NFL2022_stuffs_EPA, aes(x = week, y = epa, color = passer, linetype = passer)) +\n  geom_line(linewidth = 1.2) +\n  labs(title = \"NFL Weekly Trend of Mean EPA for Passers\",\n       x = \"Week\",\n       y = \"Mean EPA\") +\n  scale_color_manual(values = c(\"J.Allen\" = \"blue\", \"P.Mahomes\" = \"red\")) +\n  scale_linetype_manual(values = c(\"J.Allen\" = \"solid\", \"P.Mahomes\" = \"dashed\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis line plot illustrates the weekly trend of the mean value of Expected Points Added (EPA) for two excellent passers."
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html#q2f",
    "href": "posts/NFL 2022 Data/index.html#q2f",
    "title": "NFL 2022 Data",
    "section": "Q2f",
    "text": "Q2f\n\nCalculate the difference between the mean value of epa for “J.Allen” the mean value of epa for “P.Mahomes” for each value of week.\n\nAnswer:\n\nepa_difference &lt;- NFL2022_stuffs_EPA %&gt;%\n  group_by(week) %&gt;%\n  summarise(mean_epa_difference = mean(epa[passer == \"J.Allen\"]) - mean(epa[passer == \"P.Mahomes\"]))\n\nprint(epa_difference)\n\n# A tibble: 22 × 2\n    week mean_epa_difference\n   &lt;int&gt;               &lt;dbl&gt;\n 1     1             -0.169 \n 2     2              0.339 \n 3     3             -0.0763\n 4     4             -0.0803\n 5     5              0.325 \n 6     6              0.173 \n 7     7            NaN     \n 8     8            NaN     \n 9     9             -0.304 \n10    10             -0.429 \n# ℹ 12 more rows"
  },
  {
    "objectID": "posts/NFL 2022 Data/index.html#q2g",
    "href": "posts/NFL 2022 Data/index.html#q2g",
    "title": "NFL 2022 Data",
    "section": "Q2g",
    "text": "Q2g\n\nSummarize the resulting data.frame in Q2d, with the following four variables:\n\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.)\nmean_epa: Mean value of epa in 2022 for each passer\nn_pass: Number of observations for each passer\n\nThen find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\n\nAnswer:\n\npasser_summary &lt;- NFL2022_stuffs_EPA %&gt;%\n  group_by(posteam, passer) %&gt;%\n  summarise(\n    mean_epa = mean(epa, na.rm = TRUE),\n    n_pass = n()\n  )\n\n`summarise()` has grouped output by 'posteam'. You can override using the\n`.groups` argument.\n\nquantile_threshold &lt;- quantile(passer_summary$n_pass, 0.75)\n\ntop_passers &lt;- passer_summary %&gt;%\n  filter(n_pass &gt;= quantile_threshold) %&gt;%\n  arrange(desc(mean_epa)) %&gt;%\n  slice_head(n = 10)\n\nprint(top_passers)\n\n# A tibble: 29 × 4\n# Groups:   posteam [29]\n   posteam passer     mean_epa n_pass\n   &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;int&gt;\n 1 ARI     K.Murray     0.0163    465\n 2 ATL     M.Mariota    0.0251    370\n 3 BAL     L.Jackson    0.0549    398\n 4 BUF     J.Allen      0.172     785\n 5 CHI     J.Fields    -0.0455    469\n 6 CIN     J.Burrow     0.153     854\n 7 CLE     J.Brissett   0.0912    445\n 8 DAL     D.Prescott   0.147     529\n 9 DEN     R.Wilson    -0.0163    609\n10 DET     J.Goff       0.171     661\n# ℹ 19 more rows"
  },
  {
    "objectID": "danl-210-python-basic.html",
    "href": "danl-210-python-basic.html",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')\n\n\n\n\nIn Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n10.5\n\n\n\n\n\nPython supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\nThese conditions can be used in several ways, most commonly in ‘if statements’ and loops.\n\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')\n\n\n\n\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()\n\n\n\n\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "danl-210-python-basic.html#what-is-python",
    "href": "danl-210-python-basic.html#what-is-python",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')"
  },
  {
    "objectID": "danl-210-python-basic.html#variables-and-data-types",
    "href": "danl-210-python-basic.html#variables-and-data-types",
    "title": "Python Basics",
    "section": "",
    "text": "In Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n10.5"
  },
  {
    "objectID": "danl-210-python-basic.html#control-structures",
    "href": "danl-210-python-basic.html#control-structures",
    "title": "Python Basics",
    "section": "",
    "text": "Python supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\nThese conditions can be used in several ways, most commonly in ‘if statements’ and loops.\n\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')"
  },
  {
    "objectID": "danl-210-python-basic.html#functions",
    "href": "danl-210-python-basic.html#functions",
    "title": "Python Basics",
    "section": "",
    "text": "A function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()"
  },
  {
    "objectID": "danl-210-python-basic.html#lists-and-dictionaries",
    "href": "danl-210-python-basic.html#lists-and-dictionaries",
    "title": "Python Basics",
    "section": "",
    "text": "A list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "quarto-template.html",
    "href": "quarto-template.html",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "",
    "text": "oj &lt;- read_csv('https://bcdanl.github.io/data/dominick_oj.csv')\nnvars &lt;- format(round(ncol(oj), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(oj), 0), \n                nsmall=0, \n                big.mark=\",\")\nThe number of variables is 4; the number of observations is 28,947.\nRoses are red\nviolets are blue."
  },
  {
    "objectID": "quarto-template.html#data-summary",
    "href": "quarto-template.html#data-summary",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.1 Data Summary",
    "text": "2.1 Data Summary\n\nSummary statistics (Use skimr::skim())"
  },
  {
    "objectID": "quarto-template.html#data-visualization",
    "href": "quarto-template.html#data-visualization",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.2 Data Visualization",
    "text": "2.2 Data Visualization\n\noj %&gt;% \n  ggplot(aes(x = log(sales), \n             y = log(price),\n             color = brand)) +\n  geom_point(alpha = .1) +\n  geom_smooth(method = lm, se = F) +\n  facet_wrap(.~ad) +\n  theme_bw() +\n  theme(legend.position = 'top')"
  },
  {
    "objectID": "quarto-template.html#data-transformation",
    "href": "quarto-template.html#data-transformation",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.3 Data Transformation",
    "text": "2.3 Data Transformation\n\nob_sum1 &lt;- oj %&gt;% \n  group_by(brand, ad) %&gt;% \n  summarise(sales_tot = sum(sales, na.rm = T),\n            price_mean = round(mean(price, na.rm = T), 2))"
  },
  {
    "objectID": "quarto-template.html#analysis",
    "href": "quarto-template.html#analysis",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.4 Analysis",
    "text": "2.4 Analysis"
  },
  {
    "objectID": "quarto-template.html#quotes",
    "href": "quarto-template.html#quotes",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.5 Quotes",
    "text": "2.5 Quotes\n\nQuote with &gt;\n\n\n“The truth is rarely pure and never simple.”\n— Oscar Wilde"
  },
  {
    "objectID": "quarto-template.html#inserting-figures",
    "href": "quarto-template.html#inserting-figures",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.6 Inserting Figures",
    "text": "2.6 Inserting Figures\nFor a demonstration of a DANL tiger, see Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: DANL Tiger"
  },
  {
    "objectID": "quarto-template.html#inserting-a-html-page",
    "href": "quarto-template.html#inserting-a-html-page",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.7 Inserting a HTML page",
    "text": "2.7 Inserting a HTML page"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ryan Horn",
    "section": "",
    "text": "I am a second-year Data Analytics major at SUNY Geneseo with a passion for technology and problem-solving. My U.S. Army experience has strengthened my leadership, teamwork, and ability to perform under pressure. I am eager to apply my analytical skills to real-world challenges and connect with professionals to grow in the field."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Ryan Horn",
    "section": "Education",
    "text": "Education\nCandidate for Bachelor of Science in Data Analytics at SUNY Geneseo  Geneseo, NY  Aug 2023 - May 2026"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Ryan Horn",
    "section": "Experience",
    "text": "Experience\nUSARNG July 2020 - July 2026"
  },
  {
    "objectID": "danl200-hw5-Horn-Ryan.qmd/danl200-hw5-Horn-Ryan.qmd.html",
    "href": "danl200-hw5-Horn-Ryan.qmd/danl200-hw5-Horn-Ryan.qmd.html",
    "title": "danl200-hw5-Horn-Ryan.qmd",
    "section": "",
    "text": "Below is a link to my GitHub repository.\nhref: https://github.com/rhorn15/rhorn15.github.io\nBelow is a link to my website\nhref:\nhttps://rhorn15.github.io/\nThe answers for Q2 of the homework can be found in the blog section of my website or right here.\nhref: https://rhorn15.github.io/posts/NFL%202022%20Data/"
  },
  {
    "objectID": "danl200-hw5-Horn-Ryan.qmd/danl200-hw5-Horn-Ryan.qmd.html#q1a",
    "href": "danl200-hw5-Horn-Ryan.qmd/danl200-hw5-Horn-Ryan.qmd.html#q1a",
    "title": "danl200-hw5-Horn-Ryan.qmd",
    "section": "",
    "text": "Below is a link to my GitHub repository.\nhref: https://github.com/rhorn15/rhorn15.github.io\nBelow is a link to my website\nhref:\nhttps://rhorn15.github.io/\nThe answers for Q2 of the homework can be found in the blog section of my website or right here.\nhref: https://rhorn15.github.io/posts/NFL%202022%20Data/"
  }
]